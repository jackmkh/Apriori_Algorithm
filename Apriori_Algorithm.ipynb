{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "This notebook aims to demostrate how to implement Apriori algorithm to discover potential 'rules' in a data set."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a list of sets, the algorithm will find the 'rules' and present the 'rules' in the format of ｛A1, A2, …｝->｛B1, B2, …｝\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'rules' are discovered based on these two criteria: P(A1,A2,…,B1,B2,…) >= min_support and P(B1, B2, …|A1, A2, …) >= min_confident"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "min_support and min_confident are user specified values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class apriori:\n",
    "    def __init__(self, min_support, min_confidence):\n",
    "        self.sets_count = dict()\n",
    "        self.min_support_sets = None\n",
    "        self.min_support = min_support\n",
    "        self.min_confidence = min_confidence\n",
    "    \n",
    "    def get_set_count(self, data, set_candidate):\n",
    "        '''\n",
    "        Return number of occurrence of set_candidate in the data\n",
    "\n",
    "        Parameters\n",
    "        -----------\n",
    "        data: List\n",
    "            A list of records. Each records should be a set.\n",
    "        \n",
    "        set_candidate: Set\n",
    "            A set of items to be counted\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        Int:\n",
    "            Number of set_candidate in data\n",
    "        '''  \n",
    "        item_key = tuple(set_candidate)\n",
    "        if item_key not in self.sets_count:\n",
    "            item_count = 0\n",
    "            for record in data:\n",
    "                if set_candidate.issubset(record):\n",
    "                    item_count += 1\n",
    "            self.sets_count[item_key] = item_count\n",
    "        return self.sets_count[item_key]\n",
    "    \n",
    "    def gen_first_sets(self, data):\n",
    "        '''\n",
    "        Return lists of candidate sets. Each set has one item\n",
    "\n",
    "        Parameters\n",
    "        -----------\n",
    "        data: List\n",
    "            A list of records. Each records should be a set.\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        List:\n",
    "            A list of sets with length one\n",
    "        '''  \n",
    "        res = set()\n",
    "        for record in data:\n",
    "            res.update(record)\n",
    "        res = [{i} for i in res]\n",
    "        return res\n",
    "    \n",
    "    def gen_CTable(self, data, subsets):\n",
    "        '''\n",
    "        Return support_value for each item in subsets which is greater than min_support\n",
    "\n",
    "        Parameters\n",
    "        -----------\n",
    "        data: List\n",
    "            A list of records. Each records should be a set.\n",
    "        \n",
    "        subsets: List\n",
    "            A list of items that need to be counted. Each item should a set\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        Dict: \n",
    "            A dictionary mapping items in subsets and corresponding support value.\n",
    "            format: {tuple : float}\n",
    "        '''     \n",
    "        CTable = defaultdict(lambda: 0)\n",
    "        for item in subsets:\n",
    "            CTable[tuple(item)] = self.get_set_count(data, item)\n",
    "        l = len(data)\n",
    "        for k in list(CTable.keys()):\n",
    "            if CTable[k]/l < self.min_support:\n",
    "                CTable.pop(k)\n",
    "            else:\n",
    "                CTable[k] /= l\n",
    "        return CTable\n",
    "    \n",
    "    def is_super_set(self, candidate_set, recorded_sets):\n",
    "        '''\n",
    "        If any subset of candidate_set is in recorded_sets, return True.\n",
    "        e.g. candidate_set = {1,2,3}   recorded_sets = {(5,7), (9,), (1,3)}   Return: True \n",
    "        Because {1,3} is one of subset of {1,2,3} and it is in recorded_sets\n",
    "\n",
    "        Parameters\n",
    "        -----------\n",
    "        candidate_set: set\n",
    "            The set to be tested\n",
    "        \n",
    "        recorded_sets: Set\n",
    "            Set of tuples\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        Bool:\n",
    "            Whether candidate_set is super set of any set in recorded_sets\n",
    "        '''\n",
    "        l = len(candidate_set)\n",
    "        for k in range(1, l):\n",
    "            sub_candidates = list(itertools.combinations(candidate_set, k))\n",
    "            for sub_candidate in sub_candidates:\n",
    "                if sub_candidate in recorded_sets:\n",
    "                    return True\n",
    "        return False\n",
    " \n",
    "    \n",
    "    def gen_k_sets(self, prev_candidates, k):\n",
    "        '''\n",
    "        Return lists of candidate sets. Each set has k items\n",
    "\n",
    "        Parameters\n",
    "        -----------\n",
    "        prev_candidates: set\n",
    "            Set of tuples of satisfying min_support\n",
    "        \n",
    "        k: int\n",
    "            Specify the length of sets generated\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        List:\n",
    "            A list of sets with length k\n",
    "        '''\n",
    "        c_prev = [set(i) for i in prev_candidates]  # convert to list of sets\n",
    "        c_next = list(itertools.combinations(c_prev, 2)) # list of tuples of 2 sets\n",
    "        c_next = {tuple(set1.union(set2)) for set1, set2 in c_next if len(tuple(set1.union(set2))) == k}  # convert to set of tuples with length k\n",
    "        # all subsets with length k-1 of candidate should fulfill min_support\n",
    "        remove_list = []\n",
    "        for candidate in c_next:\n",
    "            sub_candidates = itertools.combinations(candidate, k-1)\n",
    "            for sub_candidate in sub_candidates:\n",
    "                if sub_candidate not in prev_candidates:\n",
    "                    remove_list.append(candidate)\n",
    "                    break\n",
    "        for candidate in remove_list:\n",
    "            c_next.remove(candidate)\n",
    "        c_next = [set(i) for i in c_next]\n",
    "        return c_next\n",
    "    \n",
    "    def get_min_support_sets(self, data):\n",
    "        '''\n",
    "        Return subsets with support greater than min_support\n",
    "\n",
    "        Parameters\n",
    "        -----------\n",
    "        data: List\n",
    "            A list of records. Each records should be a set.\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        Dict:\n",
    "            A dictionary mapping subsets and corresponding support values\n",
    "        '''\n",
    "        # Generate count table for set with length 1\n",
    "        c_dict = dict()    # c_dict[k] store the CTable of length k\n",
    "        subsets = self.gen_first_sets(data)\n",
    "        ck = self.gen_CTable(data, subsets)\n",
    "        c_dict[1] = ck\n",
    "        k=2\n",
    "        while len(c_dict[k-1]) > 1:\n",
    "            subsets = self.gen_k_sets(set(c_dict[k-1].keys()), k)\n",
    "            ck = self.gen_CTable(data, subsets)\n",
    "            c_dict[k] = ck\n",
    "            k+=1\n",
    "        self.min_support_sets = c_dict\n",
    "        return self.min_support_sets\n",
    "    \n",
    "    def get_confidence(self, data, left_set, right_set):\n",
    "        '''\n",
    "        Return confidence value for the rule 'left_set -> right_set'\n",
    "\n",
    "        Parameters\n",
    "        -----------\n",
    "        data: List\n",
    "            A list of records. Each records should be a set.\n",
    "        \n",
    "        left_set: set\n",
    "            A set of items on left hand side of rule\n",
    "        \n",
    "        right_set: set\n",
    "            A set of items on right hand side of rule\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        Float:\n",
    "            Confidence value of the rule\n",
    "        '''\n",
    "        left_count = self.get_set_count(data, left_set)\n",
    "        combined_count = self.get_set_count(data, left_set.union(right_set))\n",
    "        return combined_count/left_count\n",
    "        \n",
    "        \n",
    "    def find_rules(self, data):\n",
    "        '''\n",
    "        Return rules with confidence value greater than min_confidence\n",
    "\n",
    "        Parameters\n",
    "        -----------\n",
    "        data: List\n",
    "            A list of records. Each records should be a set.\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        Dict:\n",
    "            A dictionary mapping rules and corresponding confidence values\n",
    "        '''\n",
    "        hist = defaultdict(lambda: set())\n",
    "        res = dict()\n",
    "        l = len(data)\n",
    "        if self.min_support_sets is None:\n",
    "            self.get_min_support_sets(data)\n",
    "        for k in self.min_support_sets.keys():\n",
    "            if k == 1:\n",
    "                continue\n",
    "            for subset in self.min_support_sets[k].keys():\n",
    "                for num_left in range(1,k):   # num_left is number of items on left hand side of the rule \n",
    "                    num_right = k - num_left\n",
    "                    left_candidates = list(itertools.combinations(subset, num_left))\n",
    "                    right_candidates = list(itertools.combinations(subset, num_right))\n",
    "                    # for each combination of rules\n",
    "                    for left_candidate in left_candidates:\n",
    "                        for right_candidate in right_candidates:\n",
    "                            if set(left_candidate).issubset(set(right_candidate)) or set(right_candidate).issubset(set(left_candidate)):\n",
    "                                continue\n",
    "                            right_candidate = tuple(set(right_candidate) - set(left_candidate))\n",
    "                            # Given left_candidate, if right_candidate is superset of a 'past right_candidate' with confidence value smaller than required value,\n",
    "                            # then its confidence value must be smaller than required value\n",
    "                            if self.is_super_set(set(right_candidate), hist[left_candidate]):\n",
    "                                hist[left_candidate].add(right_candidate)\n",
    "                                continue\n",
    "                            else:\n",
    "                                confidence_val = self.get_confidence(data, set(left_candidate), set(right_candidate))\n",
    "                                support = self.get_set_count(data, set(left_candidate).union(set(right_candidate)))/l\n",
    "                                if confidence_val >= self.min_confidence:\n",
    "                                    str_output = '{} -> {}'.format(left_candidate, right_candidate)\n",
    "                                    if str_output not in res:\n",
    "                                        print('Rule: {}  Support: {}  Confidence: {}'.format(str_output, support, confidence_val))\n",
    "                                        res[str_output] = confidence_val\n",
    "                                else:\n",
    "                                    hist[left_candidate].add(right_candidate)\n",
    "        return res\n",
    "                        \n",
    "                    \n",
    "                    \n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demostration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of bag:  1\n",
      "bag = (1,),    support = 0.5\n",
      "bag = (2,),    support = 0.75\n",
      "bag = (3,),    support = 0.75\n",
      "bag = (5,),    support = 0.75\n",
      "length of bag:  2\n",
      "bag = (1, 3),    support = 0.5\n",
      "bag = (2, 3),    support = 0.5\n",
      "bag = (2, 5),    support = 0.75\n",
      "bag = (3, 5),    support = 0.5\n",
      "length of bag:  3\n",
      "bag = (2, 3, 5),    support = 0.5\n"
     ]
    }
   ],
   "source": [
    "t = [{1,3,4},{2,3,5},{1,2,3,5},{2,5}]  # input data should be a list of sets\n",
    "a = apriori(min_support=0.5, min_confidence=0.5)\n",
    "d = a.get_min_support_sets(t)  # return sets that fulfill min_support requirement\n",
    "for k, v in d.items():\n",
    "    print('length of bag: ',k)\n",
    "    for bag, support_val in list(v.items()):\n",
    "        print('bag = {},    support = {}'.format(bag,support_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rule: (1,) -> (3,)  Support: 0.5  Confidence: 1.0\n",
      "Rule: (3,) -> (1,)  Support: 0.5  Confidence: 0.6666666666666666\n",
      "Rule: (2,) -> (3,)  Support: 0.5  Confidence: 0.6666666666666666\n",
      "Rule: (3,) -> (2,)  Support: 0.5  Confidence: 0.6666666666666666\n",
      "Rule: (2,) -> (5,)  Support: 0.75  Confidence: 1.0\n",
      "Rule: (5,) -> (2,)  Support: 0.75  Confidence: 1.0\n",
      "Rule: (3,) -> (5,)  Support: 0.5  Confidence: 0.6666666666666666\n",
      "Rule: (5,) -> (3,)  Support: 0.5  Confidence: 0.6666666666666666\n",
      "Rule: (2,) -> (3, 5)  Support: 0.5  Confidence: 0.6666666666666666\n",
      "Rule: (3,) -> (2, 5)  Support: 0.5  Confidence: 0.6666666666666666\n",
      "Rule: (5,) -> (2, 3)  Support: 0.5  Confidence: 0.6666666666666666\n",
      "Rule: (2, 3) -> (5,)  Support: 0.5  Confidence: 1.0\n",
      "Rule: (2, 5) -> (3,)  Support: 0.5  Confidence: 0.6666666666666666\n",
      "Rule: (3, 5) -> (2,)  Support: 0.5  Confidence: 1.0\n"
     ]
    }
   ],
   "source": [
    "rules = a.find_rules(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider Rule: (2, 5) -> (3,)  Support: 0.5  Confidence: 0.6666666666666666"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support_value is 0.5 because there are 2 sets containing {2,5,3} out of 4 sets in data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confidence_value is 0.667 because there are 2 sets containing {2,5,3} out of 3 sets containing {2,5}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only rules with support_value > 0.5 and confidence_value > 0.5 will be printed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
